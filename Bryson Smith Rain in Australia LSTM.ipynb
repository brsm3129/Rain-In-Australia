{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1558c7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from torch import nn, optim\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "import torch.nn.functional as func\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42db093b",
   "metadata": {},
   "source": [
    "1. Deep Neural Network Concepts (1 hour)\n",
    "   - Research and summarize key concepts of deep neural networks, focusing on architectures relevant to time-series data (e.g., LSTM, GRU).\n",
    "   - Explain the advantages of deep neural networks in processing complex patterns in data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29917cb0",
   "metadata": {},
   "source": [
    "## GRU vs LSTM\n",
    "Both GRU and LSTM are based on RNN models where they feed back their own outputs into themselves in order to better learn temporal data. Default RNN models suffer from two main problems:\n",
    "* Vanishing Gradiant Problem\n",
    "* Short Term Memory Problem \n",
    "\n",
    "### GRU\n",
    "GRU has 2 Gates to control the flow of information\n",
    "* update - This gate determines the amount of information we pass along from the previous state. This is helpful for modelling rain because the weather of the day before has a sizable impact on the weather on the following day.\n",
    "* reset - This gate decides what data from the previous state we ignore. \n",
    "### LSTM\n",
    "LSTM has 3 Gates to control the flow of information\n",
    "* input - Decides what information will be stored in long term memory\n",
    "* forget - Decides which information from long term memory should be kept or discarded\n",
    "* output - This gate takes the current input, the previous long term memory and the new long term memory to produce new short term memory\n",
    "\n",
    "Deep Neural Networks have the advantage of being able to process large amounts of data and continuously improve the model. When constructed correctly, there is no bound to the amount of learning a model can accumulate, the more data, the better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67759180",
   "metadata": {},
   "source": [
    "2. Model Development with PyTorch (2 hours)\n",
    "   - Design and implement a deep neural network model using PyTorch, appropriate for the time-series nature of the dataset (consider LSTM or GRU networks).\n",
    "   - Integrate layers like dropout or batch normalization for model optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f6d09ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([39494, 11]) torch.Size([39494])\n",
      "torch.Size([16926, 11]) torch.Size([16926])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>WindSpeed9am</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>Location</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>56420.000000</td>\n",
       "      <td>56420.000000</td>\n",
       "      <td>56420.000000</td>\n",
       "      <td>56420.000000</td>\n",
       "      <td>56420.000000</td>\n",
       "      <td>56420.000000</td>\n",
       "      <td>56420.000000</td>\n",
       "      <td>56420.000000</td>\n",
       "      <td>56420.000000</td>\n",
       "      <td>56420.000000</td>\n",
       "      <td>56420.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.471445</td>\n",
       "      <td>0.529259</td>\n",
       "      <td>0.457255</td>\n",
       "      <td>0.010332</td>\n",
       "      <td>0.658741</td>\n",
       "      <td>0.210265</td>\n",
       "      <td>0.220879</td>\n",
       "      <td>0.505153</td>\n",
       "      <td>0.522107</td>\n",
       "      <td>0.493183</td>\n",
       "      <td>0.490797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.163790</td>\n",
       "      <td>0.168417</td>\n",
       "      <td>0.158424</td>\n",
       "      <td>0.034020</td>\n",
       "      <td>0.185133</td>\n",
       "      <td>0.127954</td>\n",
       "      <td>0.414843</td>\n",
       "      <td>0.292049</td>\n",
       "      <td>0.245098</td>\n",
       "      <td>0.313762</td>\n",
       "      <td>0.292751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.344140</td>\n",
       "      <td>0.401575</td>\n",
       "      <td>0.331818</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.107692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.233333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.461347</td>\n",
       "      <td>0.522310</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.598504</td>\n",
       "      <td>0.658793</td>\n",
       "      <td>0.581818</td>\n",
       "      <td>0.002910</td>\n",
       "      <td>0.790000</td>\n",
       "      <td>0.276923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Temp9am       MinTemp       MaxTemp      Rainfall   Humidity9am  \\\n",
       "count  56420.000000  56420.000000  56420.000000  56420.000000  56420.000000   \n",
       "mean       0.471445      0.529259      0.457255      0.010332      0.658741   \n",
       "std        0.163790      0.168417      0.158424      0.034020      0.185133   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.344140      0.401575      0.331818      0.000000      0.550000   \n",
       "50%        0.461347      0.522310      0.450000      0.000000      0.670000   \n",
       "75%        0.598504      0.658793      0.581818      0.002910      0.790000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "       WindSpeed9am     RainToday      Location          Year         Month  \\\n",
       "count  56420.000000  56420.000000  56420.000000  56420.000000  56420.000000   \n",
       "mean       0.210265      0.220879      0.505153      0.522107      0.493183   \n",
       "std        0.127954      0.414843      0.292049      0.245098      0.313762   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.107692      0.000000      0.280000      0.300000      0.181818   \n",
       "50%        0.200000      0.000000      0.520000      0.500000      0.454545   \n",
       "75%        0.276923      0.000000      0.760000      0.700000      0.727273   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "                Day  \n",
       "count  56420.000000  \n",
       "mean       0.490797  \n",
       "std        0.292751  \n",
       "min        0.000000  \n",
       "25%        0.233333  \n",
       "50%        0.500000  \n",
       "75%        0.733333  \n",
       "max        1.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LOAD DATA AND MAKE IT USABLE FOR PYTORCH\n",
    "url = \"./weatherAUS.csv\"\n",
    "\n",
    "column_names = [\"Date\", \"Location\", \"MinTemp\", \"MaxTemp\", \"Rainfall\", \"Evaporation\", \"Sunshine\", \"WindGustDir\", \"WindGustSpeed\", \"WindDir9am\"]\n",
    "feature_cols = []\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "#remove rows with NaN\n",
    "data = data.dropna()\n",
    "\n",
    "    \n",
    "# Had help from https://www.kaggle.com/code/data13/recurrent-neural-network-for-rain-forecasting\n",
    "# I was super lost on how to set this data up\n",
    "\n",
    "#reformat date column\n",
    "data['Date'] = data['Date'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d'))\n",
    "data['Year'] = data['Date'].dt.year\n",
    "data['Month'] = data['Date'].dt.month\n",
    "data['Day'] = data['Date'].dt.day\n",
    "\n",
    "#encode location\n",
    "le = preprocessing.LabelEncoder()\n",
    "data['Location'] = le.fit_transform(data['Location'])\n",
    "\n",
    "# encode RainToday & RainTomorrow\n",
    "data['RainToday'].replace({'No': 0, 'Yes': 1}, inplace = True)\n",
    "data['RainTomorrow'].replace({'No': 0, 'Yes': 1}, inplace = True)\n",
    "\n",
    "#normalize\n",
    "normalized = data.copy()\n",
    "for feature_name in data.select_dtypes(include=['int', 'float']).columns:\n",
    "    max_value = data[feature_name].max()\n",
    "    min_value = data[feature_name].min()\n",
    "    normalized[feature_name] = (data[feature_name] - min_value) / (max_value - min_value)\n",
    "\n",
    "#encode catagorical\n",
    "hotdata = pd.get_dummies(normalized)\n",
    "\n",
    "features = list(hotdata.columns)\n",
    "\n",
    "#print(features)\n",
    "\n",
    "\n",
    "chosen_features = [\"Temp9am\", \"MinTemp\", \"MaxTemp\", \"Rainfall\", \"Humidity9am\", \"WindSpeed9am\", \"RainToday\", \"Location\", \"Year\", \"Month\", \"Day\"]\n",
    "\n",
    "\n",
    "#Choose Features\n",
    "X = hotdata[chosen_features]\n",
    "Y = hotdata['RainTomorrow']\n",
    "\n",
    "\n",
    "#Split Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = .3, random_state = 1)\n",
    "\n",
    "X_train = torch.from_numpy(X_train.to_numpy()).float()\n",
    "y_train = torch.squeeze(torch.from_numpy(y_train.to_numpy()).float())\n",
    "\n",
    "X_test = torch.from_numpy(X_test.to_numpy()).float()\n",
    "y_test = torch.squeeze(torch.from_numpy(y_test.to_numpy()).float())\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f074fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RainModel(nn.Module):\n",
    "    def __init__(self, n_features):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=n_features, hidden_size=50, num_layers=1, batch_first=True)\n",
    "        self.linear = nn.Linear(50,1)\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "lstm = RainModel(X_train.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696a18ec",
   "metadata": {},
   "source": [
    "3. Hyperparameter Optimization (1 hour)\n",
    "   - Experiment with various hyperparameters (e.g., number of layers, hidden units, learning rate) in the PyTorch model to optimize performance.\n",
    "   - Document the process and rationale behind the chosen hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14783c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\bryso\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimiser = optim.Adam(lstm.parameters(), lr=0.001)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "X_train = X_train.to(device)\n",
    "y_train = y_train.to(device)\n",
    "\n",
    "X_test = X_test.to(device)\n",
    "y_test = y_test.to(device)\n",
    "\n",
    "lstm = lstm.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47764089",
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_tensor(t, decimal_places = 3):\n",
    "    return round(t.item(), decimal_places)\n",
    "\n",
    "\n",
    "\n",
    "def calculate_accuracy(y_true, y_pred):\n",
    "    predicted = y_pred.ge(.5).view(-1)\n",
    "    return (y_true == predicted).sum().float() / len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b9e9d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 Train set: loss: 0.255, accuracy: 0.781 Test  set: loss: 0.261, accuracy: 0.777\n",
      "epoch 100 Train set: loss: 0.159, accuracy: 0.781 Test  set: loss: 0.162, accuracy: 0.777\n",
      "epoch 200 Train set: loss: 0.146, accuracy: 0.804 Test  set: loss: 0.149, accuracy: 0.801\n",
      "epoch 300 Train set: loss: 0.142, accuracy: 0.808 Test  set: loss: 0.145, accuracy: 0.805\n",
      "epoch 400 Train set: loss: 0.141, accuracy: 0.81 Test  set: loss: 0.144, accuracy: 0.806\n",
      "epoch 500 Train set: loss: 0.14, accuracy: 0.81 Test  set: loss: 0.144, accuracy: 0.806\n",
      "epoch 600 Train set: loss: 0.14, accuracy: 0.81 Test  set: loss: 0.143, accuracy: 0.805\n",
      "epoch 700 Train set: loss: 0.139, accuracy: 0.811 Test  set: loss: 0.143, accuracy: 0.806\n",
      "epoch 800 Train set: loss: 0.139, accuracy: 0.811 Test  set: loss: 0.142, accuracy: 0.806\n",
      "epoch 900 Train set: loss: 0.138, accuracy: 0.813 Test  set: loss: 0.142, accuracy: 0.807\n"
     ]
    }
   ],
   "source": [
    "# run the model\n",
    "for epoch in range(1000):\n",
    "    y_pred = lstm(X_train)\n",
    "    y_pred = torch.squeeze(y_pred)\n",
    "    train_loss = criterion(y_pred, y_train)\n",
    "    if epoch % 100 == 0:\n",
    "        train_acc = calculate_accuracy(y_train, y_pred)\n",
    "        y_test_pred = lstm(X_test)\n",
    "        y_test_pred = torch.squeeze(y_test_pred)\n",
    "        test_loss = criterion(y_test_pred, y_test)\n",
    "        test_acc = calculate_accuracy(y_test, y_test_pred)\n",
    "        print (str('epoch ') + str(epoch) + str(' Train set: loss: ') + str(round_tensor(train_loss)) + str(', accuracy: ') + str(round_tensor(train_acc)) + str(' Test  set: loss: ') + str(round_tensor(test_loss)) + str(', accuracy: ') + str(round_tensor(test_acc)))\n",
    "    optimiser.zero_grad()\n",
    "    train_loss.backward()\n",
    "    optimiser.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c614ed61",
   "metadata": {},
   "source": [
    "4. Model Evaluation and Analysis (1 hour)\n",
    "   - Evaluate the model's performance using metrics suitable for classification tasks (accuracy, precision, recall, F1 score, and confusion matrix).\n",
    "   - Analyze the results, focusing on the modelâ€™s ability to capture patterns and make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b88612b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error\n",
      "[[29774  1073     0]\n",
      " [ 6324  2322     1]\n",
      " [    0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.97      0.89     30847\n",
      "         1.0       0.68      0.27      0.39      8647\n",
      "         2.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.81     39494\n",
      "   macro avg       0.50      0.41      0.43     39494\n",
      "weighted avg       0.79      0.81      0.78     39494\n",
      "\n",
      "Test Error\n",
      "[[12678   468     0]\n",
      " [ 2792   987     1]\n",
      " [    0     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.96      0.89     13146\n",
      "         1.0       0.68      0.26      0.38      3780\n",
      "         2.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.81     16926\n",
      "   macro avg       0.50      0.41      0.42     16926\n",
      "weighted avg       0.79      0.81      0.77     16926\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bryso\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\bryso\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\bryso\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\bryso\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\bryso\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\bryso\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#create predictions\n",
    "predict_train = lstm(X_train).detach().numpy()\n",
    "predict_test = lstm(X_test).detach().numpy()\n",
    "\n",
    "#reshape nx1 matrix to vector\n",
    "predict_train = np.reshape(predict_train, predict_train.shape[0])\n",
    "predict_test = np.reshape(predict_test, predict_test.shape[0])\n",
    "\n",
    "\n",
    "#rounds answers to 1 or 0\n",
    "predict_train = np.rint(predict_train)\n",
    "predict_test = np.rint(predict_test)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(\"Train Error\")\n",
    "print(confusion_matrix(y_train, predict_train))\n",
    "print(classification_report(y_train, predict_train))\n",
    "\n",
    "\n",
    "print(\"Test Error\")\n",
    "print(confusion_matrix(y_test, predict_test))\n",
    "print(classification_report(y_test, predict_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299a0314",
   "metadata": {},
   "source": [
    "This model leans towards predicting no rain and has a high recall score for no rain, this however is at the sacrifice to the number of times we predict rain. With a recall rate of .28 and accuracy of .68 for Yes Rain, we cannot have much confidence in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89640961",
   "metadata": {},
   "source": [
    "5. Comparative Analysis and Reporting (1 hour)\n",
    "- Compare the developed PyTorch model with the previous FCNN based model in terms of performance and learning experience.\n",
    "- Prepare a comprehensive report summarizing the approach, findings, and experiences in using PyTorch for deep learning in rainfall prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7b0d8f",
   "metadata": {},
   "source": [
    "My LSTM model performs only slightly better than my FCNN model. The accuracy of this LSTM is .81 while the accuracy of my FCNN was .79. While the FCNN model was simpler, it had the advantage of its predictions being more balanced, with similar precision and recall between True and False while the LSTM had a much better method of predicting cases where it was False but really struggled to predict cases where it would rain tomorrow.\n",
    "\n",
    "It was a very valuable experience to create these two models. Creating the FCNN showed me the importance of preparing the data and feature selection while LSTM showed me how intricate you can get with creating a model. Getting an FCNN to run with SkLearn was fairly simple and worked out of the box while PyTorch is much more hands on. I think you could get a much better model with PyTorch with more effort but SkLearn does not have that option. \n",
    "\n",
    "The Complexity added by my LSTM does not seem to have been worth the effort but potentially with more work pushing the model to learn the positive cases one could get a better model. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
